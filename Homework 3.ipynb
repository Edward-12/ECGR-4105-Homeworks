{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b318597f",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2fadcaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       212\n",
      "           1       0.94      0.97      0.95       357\n",
      "\n",
      "    accuracy                           0.94       569\n",
      "   macro avg       0.94      0.93      0.94       569\n",
      "weighted avg       0.94      0.94      0.94       569\n",
      "\n",
      "[[189  23]\n",
      " [ 10 347]]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# load the cancer dataset\n",
    "dataset = load_breast_cancer() \n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf908a73",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c1cc6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "features = pd.DataFrame(dataset.data)\n",
    "X = features.values\n",
    "#print(features.values) # features of the cancer set\n",
    "\n",
    "y = pd.DataFrame(dataset.target)\n",
    "y = y.values\n",
    "#print(y) # target of the cancer set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d7e06586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Split the data into training and test data set\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c53041a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n",
      "Precision: 0.9722222222222222\n",
      "Recall: 0.9859154929577465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test,Y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, Y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "74fd034a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9473684210526315\n",
      "Precision: 0.9333333333333333\n",
      "Recall: 0.9859154929577465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape # shape of the new dataset\n",
    "# pca.explained_variance_ratio_ # gives an array showing the importance of each component\n",
    "\n",
    "X_train_pca, X_test_pca , y_train, y_test = train_test_split(X_pca, y, train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train_pca,y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test_pca)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test,Y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, Y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3d221fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9824561403508771\n",
      "Precision: 0.9726027397260274\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape # shape of the new dataset\n",
    "# pca.explained_variance_ratio_ # gives an array showing the importance of each component\n",
    "\n",
    "X_train_pca, X_test_pca , y_train, y_test = train_test_split(X_pca, y, train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train_pca,y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test_pca)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test,Y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, Y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6d4d9e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9824561403508771\n",
      "Precision: 0.9859154929577465\n",
      "Recall: 0.9859154929577465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape # shape of the new dataset\n",
    "# pca.explained_variance_ratio_ # gives an array showing the importance of each component\n",
    "\n",
    "X_train_pca, X_test_pca , y_train, y_test = train_test_split(X_pca, y, train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train_pca,y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test_pca)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test,Y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, Y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5a399ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9912280701754386\n",
      "Precision: 0.9861111111111112\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=8)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape # shape of the new dataset\n",
    "# pca.explained_variance_ratio_ # gives an array showing the importance of each component\n",
    "\n",
    "X_train_pca, X_test_pca , y_train, y_test = train_test_split(X_pca, y, train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train_pca,y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test_pca)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test,Y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, Y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fa6fdc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9824561403508771\n",
      "Precision: 0.9859154929577465\n",
      "Recall: 0.9859154929577465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=13)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape # shape of the new dataset\n",
    "# pca.explained_variance_ratio_ # gives an array showing the importance of each component\n",
    "\n",
    "X_train_pca, X_test_pca , y_train, y_test = train_test_split(X_pca, y, train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train_pca,y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test_pca)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test,Y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, Y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "10ddcf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n",
      "Precision: 0.9722222222222222\n",
      "Recall: 0.9859154929577465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=25)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape # shape of the new dataset\n",
    "# pca.explained_variance_ratio_ # gives an array showing the importance of each component\n",
    "\n",
    "X_train_pca, X_test_pca , y_train, y_test = train_test_split(X_pca, y, train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train_pca,y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test_pca)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test,Y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, Y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, Y_pred))\n",
    "\n",
    "# make predictions\n",
    "expected = y_train\n",
    "predicted = model.predict(X_train_pca)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a76fce",
   "metadata": {},
   "source": [
    "# Problem 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7227d623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.87       169\n",
      "           1       0.91      0.94      0.92       286\n",
      "\n",
      "    accuracy                           0.90       455\n",
      "   macro avg       0.90      0.89      0.90       455\n",
      "weighted avg       0.90      0.90      0.90       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape # shape of the new dataset\n",
    "# pca.explained_variance_ratio_ # gives an array showing the importance of each component\n",
    "\n",
    "X_train_pca, X_test_pca , y_train, y_test = train_test_split(X_pca, y, train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "\n",
    "#print(\"Accuracy:\", metrics.accuracy_score(y_test,Y_pred))\n",
    "# make predictions\n",
    "expected = y_train\n",
    "predicted = model.predict(X_train_pca)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "31feda8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       169\n",
      "           1       0.92      0.94      0.93       286\n",
      "\n",
      "    accuracy                           0.91       455\n",
      "   macro avg       0.91      0.90      0.90       455\n",
      "weighted avg       0.91      0.91      0.91       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape # shape of the new dataset\n",
    "# pca.explained_variance_ratio_ # gives an array showing the importance of each component\n",
    "\n",
    "X_train_pca, X_test_pca , y_train, y_test = train_test_split(X_pca, y, train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# make predictions\n",
    "expected = y_train\n",
    "predicted = model.predict(X_train_pca)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bd12da64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89       169\n",
      "           1       0.91      0.97      0.94       286\n",
      "\n",
      "    accuracy                           0.92       455\n",
      "   macro avg       0.93      0.91      0.92       455\n",
      "weighted avg       0.92      0.92      0.92       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape # shape of the new dataset\n",
    "# pca.explained_variance_ratio_ # gives an array showing the importance of each component\n",
    "\n",
    "X_train_pca, X_test_pca , y_train, y_test = train_test_split(X_pca, y, train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# make predictions\n",
    "expected = y_train\n",
    "predicted = model.predict(X_train_pca)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "56473055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       169\n",
      "           1       0.92      0.96      0.94       286\n",
      "\n",
      "    accuracy                           0.92       455\n",
      "   macro avg       0.92      0.91      0.92       455\n",
      "weighted avg       0.92      0.92      0.92       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=8)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape # shape of the new dataset\n",
    "# pca.explained_variance_ratio_ # gives an array showing the importance of each component\n",
    "\n",
    "X_train_pca, X_test_pca , y_train, y_test = train_test_split(X_pca, y, train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# make predictions\n",
    "expected = y_train\n",
    "predicted = model.predict(X_train_pca)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f91da7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88       169\n",
      "           1       0.91      0.96      0.94       286\n",
      "\n",
      "    accuracy                           0.92       455\n",
      "   macro avg       0.92      0.90      0.91       455\n",
      "weighted avg       0.92      0.92      0.92       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=13)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape # shape of the new dataset\n",
    "# pca.explained_variance_ratio_ # gives an array showing the importance of each component\n",
    "\n",
    "X_train_pca, X_test_pca , y_train, y_test = train_test_split(X_pca, y, train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# make predictions\n",
    "expected = y_train\n",
    "predicted = model.predict(X_train_pca)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "982d7ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80       169\n",
      "           1       0.86      0.93      0.89       286\n",
      "\n",
      "    accuracy                           0.86       455\n",
      "   macro avg       0.86      0.84      0.85       455\n",
      "weighted avg       0.86      0.86      0.86       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=25)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape # shape of the new dataset\n",
    "# pca.explained_variance_ratio_ # gives an array showing the importance of each component\n",
    "\n",
    "X_train_pca, X_test_pca , y_train, y_test = train_test_split(X_pca, y, train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# make predictions\n",
    "expected = y_train\n",
    "predicted = model.predict(X_train_pca)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
